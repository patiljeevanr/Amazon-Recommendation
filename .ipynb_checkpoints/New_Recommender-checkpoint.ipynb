{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame \n",
    "import nltk\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import neighbors\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "import re\n",
    "import string\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_json(\"Automotive_5.json\",lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['asin','overall','reviewerID']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Splitting train and test data at the start\n",
    "df_train, df_test = train_test_split(df,test_size=0.2,stratify = df['reviewerID'])\n",
    "df_train = df_train.sort_index(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16378"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4095"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_original contains the copy of training sampy before pivoting \n",
    "df_original_train = df_train.copy()\n",
    "df_train = df_train.pivot(index = \"asin\" , columns = \"reviewerID\" , values = \"overall\")\n",
    "df_train = df_train.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1835, 2928)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1508, 2928)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.pivot(index = \"asin\" , columns = \"reviewerID\" , values = \"overall\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this blockck we are normalizing each rows\n",
    "\n",
    "X = df_train.values\n",
    "Y = df_train.sum(axis = 1)\n",
    "Z =df_train.count(axis =1).astype('float64')\n",
    "Y = Y.div(Z,axis=0)\n",
    "cosine\n",
    "df_new_train = df_train.sub(Y,axis=0).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting training data into our nearest neighbor model\n",
    "nbrs_train = NearestNeighbors(n_neighbors= 5, algorithm='auto',metric ='cosine').fit(df_new_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting nmeighbors and their distances for each column\n",
    "distances, indices = nbrs_train.kneighbors(df_new_train,return_distance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 9.11808290e-01, 9.45445527e-01, 9.53736362e-01,\n",
       "        9.56259112e-01],\n",
       "       [0.00000000e+00, 8.55662433e-01, 8.63069361e-01, 8.96194623e-01,\n",
       "        9.22984595e-01],\n",
       "       [0.00000000e+00, 8.33333333e-01, 8.80477139e-01, 8.87279628e-01,\n",
       "        8.89903623e-01],\n",
       "       ...,\n",
       "       [2.22044605e-16, 6.27322004e-01, 8.79028324e-01, 9.19568916e-01,\n",
       "        9.25273528e-01],\n",
       "       [0.00000000e+00, 7.39103034e-01, 8.36015988e-01, 8.84045793e-01,\n",
       "        9.30001262e-01],\n",
       "       [0.00000000e+00, 8.53614989e-01, 8.66369379e-01, 8.71413875e-01,\n",
       "        9.08996849e-01]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,  494, 1127, 1054,  896],\n",
       "       [   1, 1212, 1728,  177, 1229],\n",
       "       [   2, 1681,  404,  209, 1374],\n",
       "       ...,\n",
       "       [1832, 1604, 1770, 1752, 1463],\n",
       "       [1833,  169, 1173,  812,  755],\n",
       "       [1834,  618,  366,  436, 1529]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list for average ratings of all items\n",
    "item_avg = df_original_train.groupby(['asin']).mean()\n",
    "# item_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list for average ratings for all users\n",
    "user_avg = df_original_train.groupby(['reviewerID']).mean()\n",
    "# user_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the mean average rating for all items and all dataset\n",
    "mean_avg = df_original_train[\"overall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>B0002U26QE</td>\n",
       "      <td>5</td>\n",
       "      <td>A3EGHUQPUV6E5U</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            asin  overall      reviewerID\n",
       "1420  B0002U26QE        5  A3EGHUQPUV6E5U"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have everything, we strat testing\n",
    "df_test[4:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1835,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This item maps basically maps items with its index in training matrix so that based on that index we can get vectors from distances and indices\n",
    "\n",
    "item_map = df_new_train.index.values\n",
    "item_map.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically we need to completely this loop\n",
    "prediction_arr = []\n",
    "\n",
    "checkbi = 0\n",
    "for i in range(len(df_test)):\n",
    "#     item = np.where(item_map == df_test[i:i+1][\"asin\"].iat[0])\n",
    "#     item _ nbrs = indices[item[0]:item[0] + 1]\n",
    "#     nbrs_distances = distances[item[0]:item[0] + 1]\n",
    "    \n",
    "    item_asin = df_test[i:i+1]['asin'].iat[0]\n",
    "    item_userID = df_test[i:i+1]['reviewerID'].iat[0]\n",
    "    actual_rating = df_test[i:i+1]['overall'].iat[0]\n",
    "    \n",
    "    predicted_rating = 0\n",
    "    if item_asin in item_avg.index:\n",
    "        bi = item_avg.loc[item_asin]['overall'] - mean_avg\n",
    "        \n",
    "    else:\n",
    "        bi = 0\n",
    "    if item_userID in user_avg.index:\n",
    "        bx = user_avg.loc[item_userID]['overall'] - mean_avg\n",
    "    else:\n",
    "        bx = 0\n",
    "            \n",
    "    baseline_estimate = mean_avg + bi + bx\n",
    "    predicted_rating = baseline_estimate\n",
    "    \n",
    "    numerator = 0 \n",
    "    denomenator = 0\n",
    "    \n",
    "    if bi != 0:\n",
    "        \n",
    "        item  = np.where(item_map == df_test[i:i+1][\"asin\"].iat[0])[0][0]\n",
    "        item_nbrs = indices[item:item+1]\n",
    "        dist_nbrs = distances[item:item+1]\n",
    "#         print(item_nbrs)\n",
    "        cnt = 0;\n",
    "        k = 0\n",
    "        for j in item_nbrs:\n",
    "            \n",
    "            temp = df_original_train.loc[(df_original_train['asin'] == item_map[j[0]]) &  (df_original_train['reviewerID'] == item_userID)]\n",
    "            if(temp.size != 0):\n",
    "                checkbi+= 1\n",
    "                dist = dist_nbrs[cnt:cnt+1]\n",
    "#                 print(dist)\n",
    "    #             print(temp['overall'].values[0])\n",
    "                numerator += ((1 - dist[0][k])*(temp['overall'].values[0] - (item_avg.loc[temp['asin']]['overall'] - mean_avg) ))\n",
    "\n",
    "                denomenator += (1 - dist[0][k])\n",
    "    #             predicted_rating += (dist*temp['overall'].values[0])/dist\n",
    "            cnt = cnt + 1\n",
    "            k+= 1\n",
    "        if denomenator:\n",
    "            predicted_rating += numerator/denomenator \n",
    "    \n",
    "    prediction_arr.append(predicted_rating)\n",
    "#     print(predicted_rating)\n",
    "#     print(actual_rating - predicted_rating)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9097443635548295"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_arr = df_test['overall'].values\n",
    "mean_squared_error(actual_arr,prediction_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9538052021009475"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "sqrt(mean_squared_error(actual_arr,prediction_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1835"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_asin = df.groupby('asin').count()\n",
    "df_asin = df_asin.index.values\n",
    "len(df_asin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2928"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviewerID = df.groupby('reviewerID').count()\n",
    "df_reviewerID = df_reviewerID.index.values\n",
    "len(df_reviewerID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "for line in df_original_train.values:\n",
    "    if line[0] in df_dict:\n",
    "        df_dict[line[0]].append(line[2])\n",
    "    else:\n",
    "        df_dict[line[0]] = [line[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_for_this = []\n",
    "count = 0\n",
    "for i in range(len(df_reviewerID)):\n",
    "    for j in range(len(df_asin)):\n",
    "#         print(df_asin[i])\n",
    "        if df_asin[j] not  in  df_dict or not df_reviewerID[i] in df_dict[df_asin[j]]:\n",
    "            predict_for_this.append((df_reviewerID[i],df_asin[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_for_this = []\n",
    "# for i in range(len(df_asin)):\n",
    "#         if df_asin[i] not  in  df_dict or not \"A100WO06OQR8BQ\" in df_dict[df_asin[i]]:\n",
    "#             predict_for_this.append((\"A100WO06OQR8BQ\",df_asin[i]))\n",
    "# len(predict_for_this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_for_this\n",
    "final_prediction = {}\n",
    "\n",
    "for i in range(len(predict_for_this)):\n",
    "#__________________________________________________________________________________________________________\n",
    "# for i in range(len(predict_for_this)): This loop needs to be run instead of above one. 5352407 records: takes time\n",
    "#__________________________________________________________________________________________________________\n",
    "    \n",
    "    item_asin = predict_for_this[i][1]\n",
    "#     print(item_asin)\n",
    "    item_userID = predict_for_this[i][0]\n",
    "#     print(item_asin,item_userID)\n",
    "    \n",
    "    predicted_rating = 0\n",
    "    if item_asin in item_avg.index:\n",
    "        bi = item_avg.loc[item_asin]['overall'] - mean_avg\n",
    "    else:\n",
    "        bi = 0\n",
    "    if item_userID in user_avg.index:\n",
    "        bx = user_avg.loc[item_userID]['overall'] - mean_avg\n",
    "    else:\n",
    "        bx = 0\n",
    "            \n",
    "    baseline_estimate = mean_avg + bi + bx\n",
    "    predicted_rating = baseline_estimate\n",
    "#     print(baseline_estimate)\n",
    "    \n",
    "    numerator = 0 \n",
    "    denomenator = 0\n",
    "    \n",
    "    if bi != 0 :\n",
    "        \n",
    "        item  = np.where(item_map == item_asin)[0][0]\n",
    "        item_nbrs = indices[item:item+1]\n",
    "        dist_nbrs = distances[item:item+1]\n",
    "        cnt = 0;\n",
    "        k = 0\n",
    "        \n",
    "        for j in item_nbrs:\n",
    "            temp = df_original_train.loc[(df_original_train['asin'] == item_map[j[0]]) &  (df_original_train['reviewerID'] == item_userID)]\n",
    "            if(temp.size != 0):\n",
    "                dist = dist_nbrs[cnt:cnt+1]\n",
    "                numerator += ((1 - dist[0][k])*(temp['overall'].values[0] - (item_avg.loc[temp['asin']]['overall'] - mean_avg) ))\n",
    "\n",
    "                denomenator += (1 - dist[0][k])\n",
    "            cnt = cnt + 1\n",
    "            k+= 1\n",
    "        if denomenator:\n",
    "            predicted_rating += numerator/denomenator \n",
    "\n",
    "    if item_userID in final_prediction:\n",
    "        final_prediction[item_userID].append((item_asin,predicted_rating))\n",
    "    else:\n",
    "        final_prediction[(item_userID)] = [(item_asin,predicted_rating)]\n",
    "\n",
    "#___________________________________________________________\n",
    "#        Sort final_prediction on basis of rating\n",
    "#___________________________________________________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('prediction.json', 'w') as fp:\n",
    "    json.dump(final_prediction, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting top 10 recommendation\n",
    "for x in final_prediction:\n",
    "    final_prediction[x] = sorted(final_prediction[x],key = lambda x:x[1],reverse= True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "precision_count = 0\n",
    "recall_count = 0\n",
    "avg_precision = 0\n",
    "avg_recall = 0\n",
    "for i in user_list:\n",
    "    precision_count = 0\n",
    "    recall_count = 0\n",
    "    for j in range(10):\n",
    "        if final_prediction[i][j] in df_test['asin'].values:\n",
    "            precision_count += 1\n",
    "        if final_prediction[i][j] in (df_test.loc[df_test['reviewerID']== i]):\n",
    "            recall_count += 1\n",
    "                                                    \n",
    "    user_precision = precision_count/10\n",
    "    avg_precision+=user_precision\n",
    "    user_recall = recall_count/(len(df_test.loc[df_test['reviewerID'] == i]))\n",
    "    avg_recall+= user_recall\n",
    "pr = avg_precision/(len(user_list))\n",
    "re = avg_recall/(len(user_list))\n",
    "print(\"Precision: \")\n",
    "print(pr)\n",
    "print(\"Recall: \")\n",
    "print(re)\n",
    "print(\"F-measure: \")\n",
    "print(2*(pr)*(re)/(pr+re))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
